data = .x)))
lda_fits1 %>%
pluck("mod_01", 1)
View(lda_errors)
View(lasso_errors)
library(tidyverse)
library(modelr)
library(janitor)
library(skimr)
library(leaps) # best subset selection
library(glmnet) # ridge & lasso
library(glmnetUtils) # improves working with glmnet
set.seed(1234)
lambda_grid <- 10^seq(-2, 10, length = 200)
train_data <- clean_data_split$train[[1]]
test_data <- clean_data_split$test[[1]]
# lasso: 10-fold cv
lasso_cv <- train_data %>%
cv.glmnet(
formula = party ~ .,
data = .,
alpha = 1,
nfolds = 10,
family = "binomial"
)
plot(lasso_cv)
lasso_lambda_1se <- lasso_cv$lambda.1se
lasso_lambda_min <- lasso_cv$lambda.min
lasso_glmnet <- tibble(
train = train_data %>% list(),
test  = test_data %>% list()
) %>%
mutate(
lasso_min = map(train, ~ glmnet(party ~ ., data = .x,
alpha = 1, lambda = lasso_lambda_min, family = "binomial")),
lasso_1se = map(train, ~ glmnet(party ~ ., data = .x,
alpha = 1, lambda = lasso_lambda_1se, family = "binomial"))
) %>%
pivot_longer(cols = c(-test, -train), names_to = "model_name", values_to = "fit")
# Inspect/compare model coefficients
lasso_glmnet %>%
pluck("fit") %>%
map( ~ coef(.x) %>%
as.matrix() %>%
as.data.frame() %>%
rownames_to_column("name")) %>%
reduce(full_join, by = "name") %>%
mutate_if(is.double, ~ if_else(. == 0, NA_real_, .)) %>%
rename(lasso_min = s0.x,
lasso_1se = s0.y) %>%
knitr::kable(digits = 3)
error_rate_lasso <- function(data, model){
data %>%
mutate(pred_prob = predict(model, newdata = data, type = "response"),
pred_party = if_else(pred_prob > 0.5, "Other", "Democrat"),
error = pred_party != party) %>%
pull(error) %>%
mean()
}
lasso_errors <- lasso_glmnet %>%
mutate(test_error  = map2_dbl(test, fit, error_rate_glm)) %>%
dplyr::select(method, test_error)
lasso_errors
library(tidyverse)
library(modelr)
library(janitor)
library(skimr)
library(leaps) # best subset selection
library(glmnet) # ridge & lasso
library(glmnetUtils) # improves working with glmnet
set.seed(1234)
lambda_grid <- 10^seq(-2, 10, length = 200)
train_data <- clean_data_split$train[[1]]
test_data <- clean_data_split$test[[1]]
# lasso: 10-fold cv
lasso_cv <- train_data %>%
cv.glmnet(
formula = party ~ .,
data = .,
alpha = 1,
nfolds = 10,
family = "binomial"
)
plot(lasso_cv)
lasso_lambda_1se <- lasso_cv$lambda.1se
lasso_lambda_min <- lasso_cv$lambda.min
lasso_glmnet <- tibble(
train = train_data %>% list(),
test  = test_data %>% list()
) %>%
mutate(
lasso_min = map(train, ~ glmnet(party ~ ., data = .x,
alpha = 1, lambda = lasso_lambda_min, family = "binomial")),
lasso_1se = map(train, ~ glmnet(party ~ ., data = .x,
alpha = 1, lambda = lasso_lambda_1se, family = "binomial"))
) %>%
pivot_longer(cols = c(-test, -train), names_to = "method", values_to = "fit")
# Inspect/compare model coefficients
lasso_glmnet %>%
pluck("fit") %>%
map( ~ coef(.x) %>%
as.matrix() %>%
as.data.frame() %>%
rownames_to_column("name")) %>%
reduce(full_join, by = "name") %>%
mutate_if(is.double, ~ if_else(. == 0, NA_real_, .)) %>%
rename(lasso_min = s0.x,
lasso_1se = s0.y) %>%
knitr::kable(digits = 3)
error_rate_lasso <- function(data, model){
data %>%
mutate(pred_prob = predict(model, newdata = data, type = "response"),
pred_party = if_else(pred_prob > 0.5, "Other", "Democrat"),
error = pred_party != party) %>%
pull(error) %>%
mean()
}
lasso_errors <- lasso_glmnet %>%
mutate(test_error  = map2_dbl(test, fit, error_rate_glm)) %>%
dplyr::select(method, test_error)
lasso_errors
?pivot_longer
set.seed(1234)
lambda_grid <- 10^seq(-2, 10, length = 200)
train_data <- clean_data_split$train[[1]]
test_data <- clean_data_split$test[[1]]
# lasso: 10-fold cv
lasso_cv <- train_data %>%
cv.glmnet(
formula = party ~ .,
data = .,
alpha = 1,
nfolds = 10,
family = "binomial"
)
plot(lasso_cv)
lasso_lambda_1se <- lasso_cv$lambda.1se
lasso_lambda_min <- lasso_cv$lambda.min
lasso_glmnet <- tibble(
train = train_data %>% list(),
test  = test_data %>% list()
) %>%
mutate(
lasso_min = map(train, ~ glmnet(party ~ ., data = .x,
alpha = 1, lambda = lasso_lambda_min, family = "binomial")),
lasso_1se = map(train, ~ glmnet(party ~ ., data = .x,
alpha = 1, lambda = lasso_lambda_1se, family = "binomial"))
) %>%
pivot_longer(cols = c(-test, -train), names_to = "method", values_to = "fit")
View(lasso_glmnet)
set.seed(1234)
lambda_grid <- 10^seq(-2, 10, length = 200)
train_data <- clean_data_split$train[[1]]
test_data <- clean_data_split$test[[1]]
# lasso: 10-fold cv
lasso_cv <- train_data %>%
cv.glmnet(
formula = party ~ .,
data = .,
alpha = 1,
nfolds = 10,
family = "binomial"
)
plot(lasso_cv)
lasso_lambda_1se <- lasso_cv$lambda.1se
lasso_lambda_min <- lasso_cv$lambda.min
lasso_glmnet <- tibble(
train = train_data %>% list(),
test  = test_data %>% list()
) %>%
mutate(
lasso_min = map(train, ~ glmnet(party ~ ., data = .x,
alpha = 1, lambda = lasso_lambda_min, family = "binomial")),
lasso_1se = map(train, ~ glmnet(party ~ ., data = .x,
alpha = 1, lambda = lasso_lambda_1se, family = "binomial"))
) %>%
pivot_longer(cols = c(-test, -train), names_to = "model_name", values_to = "fit")
library(tidyverse)
library(modelr)
library(janitor)
library(skimr)
library(leaps) # best subset selection
library(glmnet) # ridge & lasso
library(glmnetUtils) # improves working with glmnet
set.seed(1234)
lambda_grid <- 10^seq(-2, 10, length = 200)
train_data <- clean_data_split$train[[1]]
test_data <- clean_data_split$test[[1]]
# lasso: 10-fold cv
lasso_cv <- train_data %>%
cv.glmnet(
formula = party ~ .,
data = .,
alpha = 1,
nfolds = 10,
family = "binomial"
)
plot(lasso_cv)
lasso_lambda_1se <- lasso_cv$lambda.1se
lasso_lambda_min <- lasso_cv$lambda.min
lasso_glmnet <- tibble(
train = train_data %>% list(),
test  = test_data %>% list()
) %>%
mutate(
lasso_min = map(train, ~ glmnet(party ~ ., data = .x,
alpha = 1, lambda = lasso_lambda_min, family = "binomial")),
lasso_1se = map(train, ~ glmnet(party ~ ., data = .x,
alpha = 1, lambda = lasso_lambda_1se, family = "binomial"))
) %>%
pivot_longer(cols = c(-test, -train), names_to = "model_name", values_to = "fit")
# Inspect/compare model coefficients
lasso_glmnet %>%
pluck("fit") %>%
map( ~ coef(.x) %>%
as.matrix() %>%
as.data.frame() %>%
rownames_to_column("name")) %>%
reduce(full_join, by = "name") %>%
mutate_if(is.double, ~ if_else(. == 0, NA_real_, .)) %>%
rename(lasso_min = s0.x,
lasso_1se = s0.y) %>%
knitr::kable(digits = 3)
error_rate_lasso <- function(data, model){
data %>%
mutate(pred_prob = predict(model, newdata = data, type = "response"),
pred_party = if_else(pred_prob > 0.5, "Other", "Democrat"),
error = pred_party != party) %>%
pull(error) %>%
mean()
}
lasso_errors <- lasso_glmnet %>%
mutate(test_error  = map2_dbl(test, fit, error_rate_glm)) %>%
dplyr::select(model_name, test_error)
lasso_errors
lda_errors
log_error
lasso_error
lasso_errors
full_join(lda_errors, log_error, lasso_errors)
full_join(lda_errors, log_error)
one <- full_join(lda_errors, log_error)
full_join(one, lasso_errors)
all_models <- full_join(one, lasso_errors) %>%
arrange(test_error)
View(all_models)
all_models <- full_join(one, lasso_errors) %>%
arrange(test_error) %>% View()
load(file = "data/data.rda")
raw_data <- da37024.0001
clean_data <- raw_data %>%
dplyr::select(
RESPID,
#response: party affiliation
Q7_1,
#demographics
# RETHNIC,
# RSTATE,
# EDUC3,
# S7, #gender
# FORBORN,
# YOUTH,
#CITIZEN,
#values
# Q2_1A, #success
# Q2_1B, #religion
# Q2_1C, #free time
# Q2_1D, #helping others
# Q2_1E, #owning home
# Q2_2B, #ethnic identity important
# Q2_2C, #gender identity important
# Q2_2D, #american identity important
#sources of information
# Q3_1,
# Q3_2_0,
# Q3_2_1,
# Q3_2_2,
# Q3_2_3,
# Q3_2_4,
# Q3_2_5,
# Q3_2_6,
# Q3A_2_1,
# Q3A_2_2,
# Q3A_2_3,
#voting
#REGISTERED,
# Q4_2,
# Q4_6,
# #favorability of candidates
# Q4_11C,
# Q4_11D,
# Q4_11E,
# Q4_11F,
#civic behavior
# Q5_1_01,
# Q5_1_02,
# Q5_1_03,
# Q5_1_04,
# Q5_1_05,
# Q5_1_06,
# Q5_1_07,
# Q5_1_08,
# Q5_1_09,
# #contact
# Q5_5,
# #religion
# RELIGIOUS,
# ALLCHRISTIAN,
#issues
Q6_1A,
#Q6_1D,
Q6_5_1,
Q6_5_2,
Q6_5_3,
Q6_5_4,
Q6_5_5,
Q6_5_6,
Q6_5_7,
# Q6_6A,
# Q6_6B,
#home and family
# Q8_1,
# Q8_2,
# Q8_6,
# Q8_8,
# EMPLOYED,
# Q8_20
)
source('~/.active-rstudio-document', echo=TRUE)
#logistic
glm_fits <- clean_data_split %>%
mutate(log_mod_01 = map(train, glm,
formula = party ~.,
family = binomial("logit")),
log_mod_02 = map(train, glm,
formula = party ~ Q6_1A + Q6_5_1 + Q6_5_2 + Q6_5_3 + Q6_5_7,
family = binomial("logit")),
log_mod_03 = map(train, glm,
formula = party ~ Q6_1A,
family = binomial("logit"))) %>%
pivot_longer(cols = contains("mod_"), names_to = "model_name", values_to =  "model_fit")
#now, for all the models
#Function for error rate
error_rate_glm <- function(data, model){
data %>%
mutate(pred_prob = predict(model, newdata = data, type = "response"),
pred_party = if_else(pred_prob > 0.5, "Other", "Democrat"),
error = pred_party != party) %>%
pull(error) %>%
mean()
}
# Function to form confusion matrix
confusion_mat_glm <- function(data, model){
data %>%
mutate(pred_prob = predict(model, newdata = data, type = "response"),
pred_party = if_else(pred_prob > 0.5, "Other", "Democrat")) %>%
count(party, pred_party) %>%
mutate(prop = n / sum(n))
}
# Calculate model error
glm_fits <- glm_fits %>%
mutate(train_error = map2_dbl(train, model_fit, error_rate_glm),
test_error  = map2_dbl(test, model_fit, error_rate_glm),
test_confusion = map2(test, model_fit, confusion_mat_glm))
log_error <- glm_fits %>%
dplyr::select(model_name, test_error) %>%
# select_if(~ !is_list(.)) %>%
arrange(test_error)
glm_fits %>%
unnest(test_confusion) %>%
dplyr::select(model_name, party, pred_party, prop)
log_error <- glm_fits %>%
dplyr::select(model_name, test_error) %>%
# select_if(~ !is_list(.)) %>%
arrange(test_error)
log_error <- glm_fits %>%
dplyr::select(model_name, test_error) %>%
# select_if(~ !is_list(.)) %>%
arrange(test_error) %>%
knit_print.trunc_mat()
View(log_error)
View(one)
glm_fits %>%
unnest(test_confusion) %>%
dplyr::select(model_name, party, pred_party, prop)
glm_fits %>%
unnest(test_confusion) %>%
dplyr::select(model_name, party, pred_party, prop) %>%
dplyr::filter(log_mod_1)
glm_fits %>%
unnest(test_confusion) %>%
dplyr::select(model_name, party, pred_party, prop) %>%
dplyr::filter(model_name = log_mod_1)
glm_fits %>%
unnest(test_confusion) %>%
dplyr::select(model_name, party, pred_party, prop) %>%
dplyr::filter(model_name == log_mod_1)
glm_fits %>%
unnest(test_confusion) %>%
dplyr::select(model_name, party, pred_party, prop) %>%
dplyr::filter(model_name == log_mod_01)
glm_fits %>%
unnest(test_confusion) %>%
dplyr::select(model_name, party, pred_party, prop) %>%
dplyr::filter(model_name == "log_mod_01")
glm_fits %>%
unnest(test_confusion) %>%
dplyr::select(model_name, party, pred_party, prop) %>%
dplyr::filter(model_name == "log_mod_01") %>%
select(-model_name) %>%
pivot_wider(names_from = pred_party, values_from = prop)
glm_fits %>%
unnest(test_confusion) %>%
dplyr::select(model_name, party, pred_party, prop) %>%
dplyr::filter(model_name == "log_mod_01") %>%
dplyr::select(-model_name) %>%
pivot_wider(names_from = pred_party, values_from = prop)
#log_mod_2 confusion matrix
glm_fits %>%
unnest(test_confusion) %>%
dplyr::select(model_name, party, pred_party, prop) %>%
dplyr::filter(model_name == "log_mod_02") %>%
dplyr::select(-model_name) %>%
pivot_wider(names_from = pred_party, values_from = prop)
<br>
# Linear Discriminant Analysis ----------------------------------------------------------------
lda_fits <- clean_data_split %>%
mutate(lda_mod_01 = map(train, ~ lda(formula = party ~.,
data = .x)),
lda_mod_02 = map(train, ~ lda(formula = party ~ Q6_1A + Q6_5_1 + Q6_5_2 + Q6_5_3 + Q6_5_7,
data = .x)),
lda_mod_03 = map(train, ~ lda(formula = party ~ Q6_1A,
data = .x))) %>%
pivot_longer(cols = contains("mod_"), names_to = "model_name", values_to = "model_fit")
# Function to calculate lda error rate
error_rate_lda <- function(data, model){
data %>%
mutate(pred_party = predict(model, newdata = data) %>%
pluck("class"),
error = pred_party != party) %>%
pull(error) %>%
mean()
}
# Function to form lda confusion matrix
confusion_mat_lda <- function(data, model){
data %>%
mutate(pred_party = predict(model, newdata = data) %>%
pluck("class")) %>%
count(party, pred_party) %>%
mutate(prop = n / sum(n))
}
# update lda_fits with error and confusion info
lda_fits <- lda_fits %>%
mutate(train_error = map2_dbl(train, model_fit, error_rate_lda),
test_error  = map2_dbl(test, model_fit, error_rate_lda),
test_confusion = map2(test, model_fit, confusion_mat_lda))
# Compare models by test_error
lda_errors <- lda_fits %>%
dplyr::select(model_name, test_error) %>%
arrange(test_error)
# Compare models by test_error
lda_fits %>%
unnest(test_confusion) %>%
dplyr::select(model_name, party, pred_party, prop)
lda_fits1 <- clean_data_split %>%
mutate(mod_01 = map(train, ~ lda(formula = party ~.,
data = .x)))
lda_fits1 %>%
pluck("mod_01", 1)
View(lda_errors)
# Compare models by test_error
lda_fits %>%
unnest(test_confusion) %>%
dplyr::select(model_name, party, pred_party, prop)
# mod 1 confusion
lda_fits %>%
unnest(test_confusion) %>%
dplyr::select(model_name, party, pred_party, prop) %>%
dplyr::filter(model_name == "lda_mod_01") %>%
dplyr::select(-model_name) %>%
pivot_wider(names_from = pred_party, values_from = prop)
# mod 2 confusion
lda_fits %>%
unnest(test_confusion) %>%
dplyr::select(model_name, party, pred_party, prop) %>%
dplyr::filter(model_name == "lda_mod_02") %>%
dplyr::select(-model_name) %>%
pivot_wider(names_from = pred_party, values_from = prop)
set.seed(1234)
lambda_grid <- 10^seq(-2, 10, length = 200)
train_data <- clean_data_split$train[[1]]
test_data <- clean_data_split$test[[1]]
# lasso: 10-fold cv
lasso_cv <- train_data %>%
cv.glmnet(
formula = party ~ .,
data = .,
alpha = 1,
nfolds = 10,
family = "binomial"
)
plot(lasso_cv)
lasso_lambda_1se <- lasso_cv$lambda.1se
lasso_lambda_min <- lasso_cv$lambda.min
lda_errors
log_error
lasso_errors
one <- full_join(lda_errors, log_error)
all_models <- full_join(one, lasso_errors) %>%
arrange(test_error)
all_models <- full_join(one, lasso_errors) %>%
arrange(test_error) %>% View()
